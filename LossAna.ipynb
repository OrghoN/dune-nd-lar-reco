{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "parameters = {'axes.labelsize': 25,\n",
    "              'axes.titlesize': 35,\n",
    "              'xtick.labelsize': 20,\n",
    "              'ytick.labelsize': 20,\n",
    "              'legend.fontsize': 20,\n",
    "              }\n",
    "plt.rcParams.update(parameters)\n",
    "\n",
    "PERSONAL_DIR = \"/cluster/tufts/minos/jwolcott/app/personal/nd/nd-lar-reco\"\n",
    "TRAIN_DIR = \"/media/hdd1/jwolcott/data/dune/nd/nd-lar-reco/train\"\n",
    "VALID_DIR = \"/media/hdd1/jwolcott/data/dune/nd/nd-lar-reco/valid\"\n",
    "\n",
    "#SAMPLE = \"uresnet+ppn-380Kevs-25Kits-batch32\"\n",
    "#SAMPLE = \"uresnet+ppn-380Kevs-50Kits-batch32\"\n",
    "#SAMPLE = \"track+showergnn-380Kevs-15Kits-batch32\"\n",
    "#SAMPLE = \"track+showergnn-380Kevs-15Kits-batch16-attempt2\"\n",
    "SAMPLE = \"track+intergnn-1400evs-1000Kits-batch8\"\n",
    "#SAMPLE = \"tests\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = os.path.join(TRAIN_DIR, SAMPLE)\n",
    "  \n",
    "csvs=[os.path.join(target_dir,f) for f in os.listdir(target_dir) if f.endswith('.csv')]\n",
    "dfs=[pd.read_csv(f) for f in csvs]\n",
    "for idx in np.argsort([df.iter.min() for df in dfs]):\n",
    "    df=dfs[idx]\n",
    "    print(csvs[idx],df.iter.min(),'=>',df.iter.max())\n",
    "df=pd.concat([dfs[idx] for idx in np.argsort([df.iter.min() for df in dfs])])\n",
    "print(sorted(df.keys()))\n",
    "print(\"losses:\", sorted(k for k in df.keys() if \"loss\" in k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import re\n",
    "\n",
    "valid_dir = os.path.join(VALID_DIR, SAMPLE, \"log_inference\")\n",
    "print(\"validation file dir:\", valid_dir)\n",
    "dfs_valid = []\n",
    "filepattern = re.compile('.*log-(\\d+).*')\n",
    "for f in pathlib.Path(valid_dir).glob(\"**/*.csv\"):\n",
    "    f = str(f)\n",
    "    matches = filepattern.match(f)\n",
    "    if not matches:\n",
    "        continue\n",
    "    \n",
    "    dfs_valid.append(pd.read_csv(f))\n",
    "    dfs_valid[-1]['iter'] = int(matches.group(1))\n",
    "\n",
    "df_valid = None\n",
    "if len(dfs_valid) > 0:\n",
    "    df_valid = pd.concat([dfs_valid[idx] for idx in np.argsort([df.iter.min() for df in dfs_valid])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotdir=\"/media/hdd1/jwolcott/data/dune/nd/nd-lar-reco/plots/\" + SAMPLE\n",
    "if not os.path.isdir(plotdir):\n",
    "    os.mkdir(plotdir)\n",
    "\n",
    "loss_types = {\n",
    "#      \"ppn_loss\": \"PPN loss\",\n",
    "#      \"seg_loss\": \"SS loss\",\n",
    "#    \"uresnet_loss\": \"SS loss\",\n",
    "#    \"loss_ppn1\": \"PPN1 loss\",\n",
    "#    \"loss_ppn2\": \"PPN2 loss\",\n",
    "#    \"shower_edge_loss\": \"Shower GNN edge loss\",\n",
    "#    \"shower_node_loss\": \"Shower GNN node loss\",\n",
    "#    \"track_edge_loss\": \"Track GNN edge loss\",\n",
    "    \"inter_edge_loss\": \"Interaction GNN edge loss\"\n",
    "#    \"loss\": \"Total loss\",\n",
    "}\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(12,8),facecolor='w')\n",
    "sdf=df\n",
    "\n",
    "colors = {}\n",
    "test = {}\n",
    "for loss_name, loss_title in loss_types.items():\n",
    "    print(\"considering loss:\", loss_name)\n",
    "    if loss_name in sdf:\n",
    "        p = ax.plot(sdf.iter, sdf[loss_name], label=loss_title + \" (train)\", alpha=0.75)\n",
    "        if loss_title not in colors:\n",
    "            colors[loss_title] = p[-1].get_color()\n",
    "\n",
    "    if df_valid and loss_name in df_valid:\n",
    "        test[loss_title] = ax.plot(df_valid.iter, df_valid[loss_name], label=loss_title + \" (test)\", marker='o')[0]\n",
    "\n",
    "# go back and set the \"test\" samples correctly\n",
    "for title, color in colors.items():\n",
    "    if title in test:\n",
    "        test[title].set_color(color)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "#ax.set_ylim(1e-10,1)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "\n",
    "for ext in (\"pdf\", \"png\"):\n",
    "    fig.savefig(os.path.join(plotdir, \"loss.\" + ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(12,8),facecolor='w')\n",
    "sdf=df.query('iter<15000')\n",
    "ax.plot(sdf.iter,sdf.ppn_loss, label=\"PPN loss\")\n",
    "ax.plot(sdf.iter,sdf.loss, label=\"total loss\")\n",
    "#ax.plot(sdf.iter,sdf.frag_edge_loss)\n",
    "#ax.plot(sdf.iter,sdf.frag_node_loss)\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylim(0.01,5.0)\n",
    "ax.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(12,8),facecolor='w')\n",
    "# ax.plot(df[\"fraction_positives_ppn1\"], label=\"positives PPN1\")\n",
    "# ax.plot(df[\"fraction_positives_ppn2\"], label=\"positives PPN2\")\n",
    "ax.plot(df[\"shower_node_accuracy\"], label=\"shower node accuracy\")\n",
    "ax.plot(df[\"shower_edge_accuracy\"], label=\"shower edge accuracy\")\n",
    "ax.plot(df[\"track_edge_accuracy\"], label=\"track edge accuracy\")\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "# ax.set_ylabel(\"Fraction\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "times = []\n",
    "pat = re.compile(r\".*train time.*\\(([0-9.]+) \\[s\\]\\).*\")\n",
    "for line in open(os.path.join(TRAIN_DIR, \"train-inter-gnn.20210718.log\")):\n",
    "    matches = pat.match(line)\n",
    "    if matches:\n",
    "        times.append(float(matches.group(1)))\n",
    "\n",
    "fig,ax=plt.subplots(figsize=(12,8),facecolor='w')\n",
    "ax.plot(times)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Train time (s)\")\n",
    "\n",
    "times = np.array(times)\n",
    "#print(times)\n",
    "start_place = 15\n",
    "avg_time = sum(times[start_place:])/len(times[start_place:])\n",
    "plt.plot((start_place, len(times)-1), (avg_time, avg_time), label=\"y=%.0f\" % avg_time )\n",
    "\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
